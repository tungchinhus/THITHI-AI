"""
Script ƒë∆°n gi·∫£n ƒë·ªÉ download ONNX model t·ª´ Hugging Face
S·ª≠ d·ª•ng huggingface_hub ƒë·ªÉ download tr·ª±c ti·∫øp
"""

import os
import sys
from pathlib import Path

# Fix encoding cho Windows console
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

def main():
    print("=" * 60)
    print("Download ONNX Model t·ª´ Hugging Face")
    print("=" * 60)
    print()
    
    # C√†i ƒë·∫∑t huggingface_hub n·∫øu ch∆∞a c√≥
    try:
        from huggingface_hub import hf_hub_download, list_repo_files
    except ImportError:
        print("üì¶ ƒêang c√†i ƒë·∫∑t huggingface_hub...")
        os.system(f"{sys.executable} -m pip install huggingface_hub --quiet")
        try:
            from huggingface_hub import hf_hub_download, list_repo_files
        except ImportError:
            print("‚ùå Kh√¥ng th·ªÉ c√†i ƒë·∫∑t huggingface_hub")
            return
    
    model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    output_dir = Path("C:/SQLServerModels")
    output_file = output_dir / "embedding_model.onnx"
    
    print(f"üì• ƒêang t√¨m model: {model_name}")
    print(f"üìÅ Output: {output_file}")
    print()
    
    # T·∫°o th∆∞ m·ª•c output
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"‚úÖ ƒê√£ t·∫°o th∆∞ m·ª•c: {output_dir}")
    print()
    
    # Ki·ªÉm tra files trong repo
    print("üîç ƒêang ki·ªÉm tra files trong repository...")
    try:
        files = list(list_repo_files(model_name))
        print(f"‚úÖ T√¨m th·∫•y {len(files)} files trong repository")
        
        # T√¨m file ONNX
        onnx_files = [f for f in files if f.endswith('.onnx')]
        if onnx_files:
            print(f"‚úÖ T√¨m th·∫•y {len(onnx_files)} file ONNX:")
            for f in onnx_files:
                print(f"   - {f}")
            print()
            print(f"üì• ƒêang download: {onnx_files[0]}...")
            
            # Download file ONNX ƒë·∫ßu ti√™n
            downloaded_file = hf_hub_download(
                repo_id=model_name,
                filename=onnx_files[0],
                local_dir=str(output_dir)
            )
            
            # Rename n·∫øu c·∫ßn
            downloaded_path = Path(downloaded_file)
            if downloaded_path.name != output_file.name:
                if output_file.exists():
                    output_file.unlink()
                downloaded_path.rename(output_file)
            
            print(f"‚úÖ ƒê√£ download th√†nh c√¥ng!")
            print(f"üìÅ File: {output_file}")
            print(f"üìä Size: {output_file.stat().st_size / (1024*1024):.2f} MB")
            print()
            print("=" * 60)
            print("‚úÖ HO√ÄN T·∫§T!")
            print("=" * 60)
            print()
            print("B∆∞·ªõc ti·∫øp theo:")
            print("1. Ch·∫°y script CREATE_ONNX_MODEL.sql trong SQL Server")
            print("2. Test v·ªõi: SELECT AI_GENERATE_EMBEDDINGS('local_onnx_embeddings', NULL, 'Test')")
            print()
            
        else:
            print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file ONNX trong repository")
            print()
            print("C√°c files c√≥ s·∫µn:")
            for f in files[:10]:  # Hi·ªÉn th·ªã 10 files ƒë·∫ßu
                print(f"   - {f}")
            if len(files) > 10:
                print(f"   ... v√† {len(files) - 10} files kh√°c")
            print()
            print("üí° Model n√†y kh√¥ng c√≥ s·∫µn ONNX version.")
            print("   C·∫ßn convert t·ª´ PyTorch sang ONNX.")
            print("   Ch·∫°y script: download_onnx_model.py (s·∫Ω convert t·ª± ƒë·ªông)")
            
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
        print()
        print("üí° Th·ª≠ ch·∫°y script: download_onnx_model.py (s·∫Ω convert t·ª´ PyTorch)")

if __name__ == "__main__":
    main()
